# üéôÔ∏è Voice Authentication Project (ECAPA-TDNN + Custom Classifier)

---

## üìå English

### Project Overview
This repository demonstrates **speaker verification** and **multi-speaker identification** using:
- Pretrained ECAPA-TDNN embeddings (SpeechBrain)
- Custom trained classifier (Logistic Regression / SVM)
- Real-time recognition with microphone

### Repository Structure
```
Data/                # Example dataset (contains one folder per speaker, e.g. Tima/)
models/sid_multi/    # Saved trained classifier and label map
scripts/             # Training, evaluation, real-time and preprocessing scripts
requirements.txt     # Python dependencies
.gitignore           # Ignore rules
README.md            # Documentation (this file)
```

### Scripts
- **Convert script.py** ‚Üí Converts audio files to WAV 16kHz mono, trims silence  
- **train_speaker_id.py** ‚Üí Extracts embeddings and trains classifier on voices  
- **evaluate_voice_verification.py** ‚Üí Evaluates verification metrics (FAR/FRR, threshold)  
- **realtime_speaker.py** ‚Üí Real-time speaker recognition with microphone  

### Quick Start
1. Put your audio in `Data/<SpeakerName>/` (each folder = 1 person).  
   Example: `Data/Tima/T1.wav`
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Train the classifier:
   ```bash
   python scripts/train_speaker_id.py
   ```
4. Test in real time:
   ```bash
   python scripts/realtime_speaker.py
   ```

---

## üìå –†—É—Å—Å–∫–∏–π

### –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
–≠—Ç–æ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç **–≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—é –≥–æ–ª–æ—Å–∞** –∏ **–∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–ø–∏–∫–µ—Ä–æ–≤** —Å –ø–æ–º–æ—â—å—é:
- –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ ECAPA-TDNN (SpeechBrain)
- –°–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ (Logistic Regression / SVM)
- –†–∞–±–æ—Ç—ã –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —á–µ—Ä–µ–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞
```
Data/                # –î–∞—Ç–∞—Å–µ—Ç (–∫–∞–∂–¥—ã–π —Å–ø–∏–∫–µ—Ä –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π –ø–∞–ø–∫–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä Tima/)
models/sid_multi/    # –û–±—É—á–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏ –∫–∞—Ä—Ç–∞ –º–µ—Ç–æ–∫
scripts/             # –°–∫—Ä–∏–ø—Ç—ã –æ–±—É—á–µ–Ω–∏—è, —Ç–µ—Å—Ç–∞, —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
requirements.txt     # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ Python
.gitignore           # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º—ã–µ —Ñ–∞–π–ª—ã
README.md            # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
```

### –°–∫—Ä–∏–ø—Ç—ã
- **Convert script.py** ‚Üí –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ –≤ WAV 16kHz mono, —É–¥–∞–ª–µ–Ω–∏–µ —Ç–∏—à–∏–Ω—ã  
- **train_speaker_id.py** ‚Üí –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ –æ–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞  
- **evaluate_voice_verification.py** ‚Üí –û—Ü–µ–Ω–∫–∞ –º–µ—Ç—Ä–∏–∫ (FAR/FRR, –ø–æ–¥–±–æ—Ä –ø–æ—Ä–æ–≥–∞)  
- **realtime_speaker.py** ‚Üí –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —á–µ—Ä–µ–∑ –º–∏–∫—Ä–æ—Ñ–æ–Ω  

### –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç
1. –ü–æ–º–µ—Å—Ç–∏—Ç–µ –∞—É–¥–∏–æ –≤ `Data/<–ò–º—è–°–ø–∏–∫–µ—Ä–∞>/` (–æ–¥–Ω–∞ –ø–∞–ø–∫–∞ = –æ–¥–∏–Ω —á–µ–ª–æ–≤–µ–∫).  
   –ü—Ä–∏–º–µ—Ä: `Data/Tima/T1.wav`
2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
   ```bash
   pip install -r requirements.txt
   ```
3. –û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å:
   ```bash
   python scripts/train_speaker_id.py
   ```
4. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ:
   ```bash
   python scripts/realtime_speaker.py
   ```

---

## üìå O‚Äòzbekcha

### Loyihaning tavsifi
Ushbu loyiha **ovozni tekshirish** va **bir nechta spikerlarni aniqlash** imkoniyatini ko‚Äòrsatadi:
- Oldindan o‚Äòqitilgan ECAPA-TDNN modelidan foydalanadi (SpeechBrain)
- Maxsus klassifikator (Logistic Regression / SVM)
- Mikrofon orqali real vaqt rejimida ishlash

### Tuzilishi
```
Data/                # Dastlabki dataset (har bir spiker alohida papkada, masalan Tima/)
models/sid_multi/    # O‚Äòqitilgan klassifikator va label_map
scripts/             # O‚Äòqitish, test, real vaqt va konvertatsiya skriptlari
requirements.txt     # Python kutubxonalari
.gitignore           # Git uchun ignore fayli
README.md            # Hujjat
```

### Skriptlar
- **Convert script.py** ‚Üí Audio fayllarni WAV 16kHz mono ga o‚Äòtkazish, sokinlikni kesish  
- **train_speaker_id.py** ‚Üí Embeddinglarni ajratish va klassifikatorni o‚Äòqitish  
- **evaluate_voice_verification.py** ‚Üí Baholash metrikalari (FAR/FRR, threshold)  
- **realtime_speaker.py** ‚Üí Mikrofon orqali real vaqt rejimida tanib olish  

### Tezkor start
1. Audio fayllarni `Data/<SpeakerName>/` ga joylang (har bir papka = bitta odam).  
   Masalan: `Data/Tima/T1.wav`
2. Kutubxonalarni o‚Äòrnating:
   ```bash
   pip install -r requirements.txt
   ```
3. Modelni o‚Äòqiting:
   ```bash
   python scripts/train_speaker_id.py
   ```
4. Real vaqt rejimida sinab ko‚Äòring:
   ```bash
   python scripts/realtime_speaker.py
   ```

---

## üë§ Author
**Temur Eshmurodov**
